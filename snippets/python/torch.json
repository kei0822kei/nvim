{
  "torch model": {
    "prefix": "torch_model",
    "body": [
      "from torch import nn",
      "",
      "",
      "class ${1:ModelName}(nn.Module):",
      "    def __init__(self):",
      "        super().__init__()",
      "        self.flatten = nn.Flatten()",
      "        self.linear_relu_stack = nn.Sequential(",
      "            nn.Linear(28 * 28, 512),",
      "            nn.ReLU(),",
      "            nn.Linear(512, 512),",
      "            nn.ReLU(),",
      "            nn.Linear(512, 10),",
      "        )",
      "        $0",
      "",
      "    def forward(self, x):",
      "        x = self.flatten(x)",
      "        logits = self.linear_relu_stack(x)",
      "        return logits"
    ]
  },
  "torch dataset": {
    "prefix": "torch_dataset",
    "body": [
      "from torch.utils.data import Dataset",
      "",
      "",
      "class ${1:DatsetName}(Dataset):",
      "    def __init__(self, data_lst):",
      "        self.data_lst = data_lst",
      "",
      "    def __len__(self):",
      "        return len(self.data_lst)",
      "",
      "    def __getitem__(self, idx):",
      "        # idx: slice object",
      "        return self.data_lst[idx]",
      "$0"
    ]
  },
  "torch dataloader": {
    "prefix": "torch_dataloader",
    "body": [
      "from torch.utils.data import DataLoader",
      "",
      "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)",
      "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)",
      "$0"
    ]
  },
  "torch train and eval": {
    "prefix": "torch_train_eval",
    "body": [
      "import torch",
      "from torch import nn",
      "from torch.utils.data import Dataset",
      "",
      "",
      "def train_loop(dataloader, model, loss_fn, optimizer):",
      "    size = len(dataloader.dataset)",
      "    # Set the model to training mode - important for batch normalization and dropout layers",
      "    # Unnecessary in this situation but added for best practices",
      "    model.train()",
      "    for batch, (X, y) in enumerate(dataloader):",
      "        # Compute prediction and loss",
      "        pred = model(X)",
      "        loss = loss_fn(pred, y)",
      "",
      "        # Backpropagation",
      "        loss.backward()",
      "        optimizer.step()",
      "        optimizer.zero_grad()",
      "",
      "        if batch % 100 == 0:",
      "            loss, current = loss.item(), batch * batch_size + len(X)",
      "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")",
      "",
      "",
      "def test_loop(dataloader, model, loss_fn):",
      "    # Set the model to evaluation mode - important for batch normalization and dropout layers",
      "    # Unnecessary in this situation but added for best practices",
      "    model.eval()",
      "    size = len(dataloader.dataset)",
      "    num_batches = len(dataloader)",
      "    test_loss, correct = 0, 0",
      "",
      "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode",
      "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True",
      "    with torch.no_grad():",
      "        for X, y in dataloader:",
      "            pred = model(X)",
      "            test_loss += loss_fn(pred, y).item()",
      "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()",
      "",
      "    test_loss /= num_batches",
      "    correct /= size",
      "    print(",
      "        f\"Test Error: \n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \n\"",
      "    )",
      "",
      "",
      "loss_fn = nn.CrossEntropyLoss()",
      "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)",
      "",
      "epochs = 10",
      "for t in range(epochs):",
      "    print(f\"Epoch {t+1}\n-------------------------------\")",
      "    train_loop(train_dataloader, model, loss_fn, optimizer)",
      "    test_loop(test_dataloader, model, loss_fn)",
      "print(\"Done!\")",
      "$0"
    ]
  },
  "torch save and load": {
    "prefix": "torch_save_load",
    "body": [
      "import torch",
      "",
      "torch.save(${1:model}.to(\"cpu\").state_dict(), \"model_weights.pth\")",
      "${1:model}.load_state_dict(torch.load(\"model_weights.pth, weights_only=True\"))",
      "${1:model}.eval()",
      "$0"
    ]
  }
}
