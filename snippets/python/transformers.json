{
  "bert embedding": {
    "prefix": "transformers_bert_embedding",
    "body": [
      "import torch",
      "from torch.utils.data import DataLoader",
      "from transformers import AutoModel, AutoTokenizer",
      "from tqdm import tqdm",
      "",
      "MODEL_PATH = \"${1:model_path}\"",
      "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")",
      "BATCH_SIZE = ${2:batch_size}",
      "",
      "",
      "def build_embedding_vec(texts, tokenizer, model):",
      "    dataloader = DataLoader(texts, batch_size=BATCH_SIZE, shuffle=False)",
      "    out = []",
      "    with torch.no_grad():",
      "        for batch in tqdm(dataloader):",
      "            x = tokenizer(batch, padding=True, truncation=True, return_tensors=\"pt\").to(",
      "                DEVICE",
      "            )",
      "            x = model(**x).last_hidden_state[:, 0, :].detach().cpu()",
      "            out.append(x)",
      "        out = torch.concatenate(out).numpy()",
      "    return out",
      "",
      "",
      "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, local_files_only=True)",
      "model = AutoModel.from_pretrained(MODEL_PATH, local_files_only=True).to(DEVICE)",
      "$0"
    ]
  }
}
